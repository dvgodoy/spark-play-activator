Spark + Play activator template
===============================

This is a [Typesafe Activator](http://typesafe.com/platform/getstarted) template to demonstrate [Apache Spark](http://spark.apache.org) and Play.

# Motivation

The original template was modified so it could be run with Spark in standalone cluster mode.

In app/demo/SparkCommons, change <MASTER_IP> and <MASTER_PORT> to your corresponding Spark Master configurations.

# Pre-Requisites

In order to have a fully functional Spark standalone cluster, you may follow a very good tutorial on installing and configuring it, which can be found [here](http://mbonaci.github.io/mbo-spark/#omg-i-have-a-running-spark-in-my-home).

Please note that its instructions regarding building Spark from source are somewhat outdated. Please refer to Spark 1.4.1 section below.

## Scala 2.11.6
This template was tested using Scala 2.11.6 which can be found [here](http://downloads.typesafe.com/scala/2.11.6/scala-2.11.6.tgz).

## Spark 1.4.1
This template was tested using Spark 1.4.1 built from source using Scala 2.11.6.
Please find Spark 1.4.1 source code [here](http://www.apache.org/dyn/closer.lua/spark/spark-1.4.1/spark-1.4.1.tgz).
To build it, uncompress it in a folder of your choice and then run the following commands:

./dev/change-scala-version.sh 2.11

mvn -Pyarn -Phadoop-2.6 -Dscala-2.11 -DskipTests clean package

It is worth noticing that even if you do not use Hadoop, the version used by Spark MUST match the version used by the Play application (in our case, 2.6).

You will receive LOTS of warnings during the build process (which can take up to 30 minutes) but it is safe to ignore them.

## Play Framework 2.4.3
This template was tested using Typesafe Activator 2.4.3 which can be found [here](https://downloads.typesafe.com/typesafe-activator/1.3.6/typesafe-activator-1.3.6-minimal.zip).

# The AKKA version conflict

Both Spark and Play have dependencies on Akka, but they use different versions.
While com.typesafe.akka:akka-actor_2.11 and com.typesafe.akka:akka-slf4j_2.11 versions are 2.3.11, org.spark-project.akka:akka-actor_2.11 and org.spark-project.akka:akka-slf4j_2.11 versions are 2.3.4-spark.

This is the source of countless errors when trying to run a Play application in a Spark standalone cluster. It turns out that, depending on the order in which those 4 jars appear on the classpath generated by the Play framework, it may work just fine or not at all.

So, it is absolutely necessary that the "org.spark-project.akka" jars come first in the classpath for the application to work.

I accomplished this by creating a LIB folder and placing both jars inside so they will be added first to the classpath. If you know a better way to solve this problem, please let me know.

# Running with Spark local

If you want to, you may use Spark in local mode just changing the parameter of the setMaster function to "local[*]".

In this setting, you will be able to run the application from an IDE or through the "activator run" command.

# Running with Spark standalone cluster

I suppose that is the reason you have got this far :-)

So, you have to generate a standalone application using the "activator dist" command. It will generate a huge zip file containing all jars needed for your application.

Please find the zip file in the [application folder]/target/universal folder. Unzip it to a location of your choice and run the application with "bash ./bin/play-spark-activator".

The NettyServer will start listening on port 9000 and you will be able to access your application on the web browser.

Do not forget to start Spark master and slaves (you may use ./sbin/start-all.sh in the Spark folder).

# The Application

This is a very simple application which creates an RDD containing all numbers from 1 to 1000.

You may check for the total number of elements in the RDD with [http://localhost:9000/count](http://localhost:9000/count), show them all with [http://localhost:9000/list](http://localhost:9000/list) or calculate the sum of the first 10 numbers with [http://localhost:9000/sum/10](http://localhost:9000/sum/10). Please note that 10 is parameter which you can change to calculate the sum up to a different number.